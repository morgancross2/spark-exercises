{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9473663-017b-41ba-84bc-04e069b42d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql.functions import * \n",
    "\n",
    "from env import conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fd3a4bf-c493-4aa6-b37e-7932239c2187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/22 14:10:59 WARN Utils: Your hostname, Morgans-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.0.202 instead (on interface en0)\n",
      "22/10/22 14:10:59 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/22 14:11:00 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/10/22 14:11:01 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "spark = pyspark.sql.SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a30460-31ae-4e54-b94c-fbb2c23c7f3f",
   "metadata": {},
   "source": [
    "1. Read the case, department, and source data into their own spark dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af1a60bb-8c80-4d12-aa0f-f42e9850ed50",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = conn('311_data')\n",
    "q1 = 'SELECT * FROM cases'\n",
    "q2 = 'SELECT * FROM dept'\n",
    "q3 = 'SELECT * FROM source'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "413d9eaf-ee68-40ef-8458-40a866551558",
   "metadata": {},
   "outputs": [],
   "source": [
    "cases = pd.read_sql(q1, url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab72949f-9ae4-4940-9c91-13020d3b5f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dept = pd.read_sql(q2, url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8f022db-982b-40de-855a-adcd23951e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "source = pd.read_sql(q3, url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3cc63fe4-ab12-44d6-b391-752e14e2b99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cases = spark.createDataFrame(cases)\n",
    "dept = spark.createDataFrame(dept)\n",
    "source = spark.createDataFrame(source)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021ac540-0bdb-403a-afc3-a6c97556807e",
   "metadata": {},
   "source": [
    "2. Let's see how writing to the local disk works in spark:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c72e3a-0e85-4862-bfec-b3f658ceafb8",
   "metadata": {},
   "source": [
    "- Write the code necessary to store the source data in both csv and json format, store these as sources_csv and sources_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97b3d8ca-d608-47ca-9865-9a29c266fe40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "source.write.json('data/sources_json', mode='overwrite')\n",
    "source.write.csv('data/sources_csv', mode='overwrite', header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11e3761-ccfe-420b-a7e8-8bca773e8193",
   "metadata": {},
   "source": [
    "- Inspect your folder structure. What do you notice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "facea72b-12c0-43ad-85c0-f8e7d8d6358a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# breaks it down to multiple files in a folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4016c790-6769-4b33-ae9c-fbe56b7f916c",
   "metadata": {},
   "source": [
    "3. Inspect the data in your dataframes. Are the data types appropriate? Write the code necessary to cast the values to the appropriate types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a8761ca-244e-474e-af91-e728cc01ec0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/22 14:13:36 WARN TaskSetManager: Stage 2 contains a task of very large size (15174 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/22 14:13:40 WARN PythonRunner: Detected deadlock while completing task 0.0 in stage 2 (TID 20): Attempting to kill Python Worker\n",
      "-RECORD 0------------------------------------\n",
      " case_id              | 1014127332           \n",
      " case_opened_date     | 1/1/18 0:42          \n",
      " case_closed_date     | 1/1/18 12:29         \n",
      " SLA_due_date         | 9/26/20 0:42         \n",
      " case_late            | NO                   \n",
      " num_days_late        | -998.5087616         \n",
      " case_closed          | YES                  \n",
      " dept_division        | Field Operations     \n",
      " service_request_type | Stray Animal         \n",
      " SLA_days             | 999.0                \n",
      " case_status          | Closed               \n",
      " source_id            | svcCRMLS             \n",
      " request_address      | 2315  EL PASO ST,... \n",
      " council_district     | 5                    \n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "cases.show(1, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c8d2b3f-324c-49f4-ad7e-9a7d0f5faff4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('case_id', 'bigint'),\n",
       " ('case_opened_date', 'string'),\n",
       " ('case_closed_date', 'string'),\n",
       " ('SLA_due_date', 'string'),\n",
       " ('case_late', 'string'),\n",
       " ('num_days_late', 'double'),\n",
       " ('case_closed', 'string'),\n",
       " ('dept_division', 'string'),\n",
       " ('service_request_type', 'string'),\n",
       " ('SLA_days', 'double'),\n",
       " ('case_status', 'string'),\n",
       " ('source_id', 'string'),\n",
       " ('request_address', 'string'),\n",
       " ('council_district', 'bigint')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cases.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e7604309-b913-4d29-8270-370647b10504",
   "metadata": {},
   "outputs": [],
   "source": [
    "cases = cases.withColumnRenamed('SLA_due_date', 'case_due_date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "77d9d2ce-c029-4704-854b-b62e84d05d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "cases = cases.withColumn('case_closed',\n",
    "             expr('case_closed ==\"YES\"')\n",
    "             ).withColumn('case_late',\n",
    "                         expr('case_late == \"YES\"'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7b4e192b-0179-44fe-a3bd-2f5ce0ed239f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cases = cases.withColumn('council_district',\n",
    "             col('council_district').cast('string')\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eef7fbe0-88b3-4e7b-8692-a01575bf7e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fmt = 'M/d/yy H:m'\n",
    "\n",
    "cases = (\n",
    "    cases.withColumn('case_opened_date', to_timestamp('case_opened_date', fmt))\n",
    "    .withColumn('case_closed_date', to_timestamp('case_closed_date', fmt))\n",
    "    .withColumn('case_due_date', to_timestamp('case_due_date', fmt))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "609202ef-fe8c-4b5e-ab77-603e090eb063",
   "metadata": {},
   "outputs": [],
   "source": [
    "cases = cases.withColumn('request_address',\n",
    "              trim(lower('request_address')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "54a16e33-bcc3-4e70-a6e7-c12c0ccdb5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cases = cases.withColumn('case_age',\n",
    "              datediff(current_timestamp(), 'case_opened_date'))\n",
    "cases = cases.withColumn('days_to_close',\n",
    "              datediff('case_closed_date', 'case_opened_date'))\n",
    "cases = cases.withColumn('case_lifetime',\n",
    "             when(expr('! case_closed'),\n",
    "                 col('case_age')\n",
    "                 )\n",
    "             .otherwise(col('days_to_close'))\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de05f58-e710-4b47-b0c4-c867d5f6503c",
   "metadata": {},
   "source": [
    "1. How old is the latest (in terms of days past SLA) currently open issue? How long has the oldest (in terms of days since opened) currently opened issue been open?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "68d0fbad-962e-4f21-ad6f-65b36afd5ee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['case_id',\n",
       " 'case_opened_date',\n",
       " 'case_closed_date',\n",
       " 'case_due_date',\n",
       " 'case_late',\n",
       " 'num_days_late',\n",
       " 'case_closed',\n",
       " 'dept_division',\n",
       " 'service_request_type',\n",
       " 'SLA_days',\n",
       " 'case_status',\n",
       " 'source_id',\n",
       " 'request_address',\n",
       " 'council_district',\n",
       " 'case_age',\n",
       " 'days_to_close',\n",
       " 'case_lifetime']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cases.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "258b89bb-36c5-413f-b84d-fdb5a9ff7edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/24 09:31:35 WARN TaskSetManager: Stage 14 contains a task of very large size (15174 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 13:===============> (9 + 1) / 10][Stage 14:===============> (9 + 1) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+\n",
      "|case_closed|case_lifetime|\n",
      "+-----------+-------------+\n",
      "|      false|         2122|\n",
      "|      false|         2122|\n",
      "+-----------+-------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 13:===================================================>     (9 + 1) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/24 09:32:10 ERROR PythonRunner: Python worker exited unexpectedly (crashed)\n",
      "java.net.SocketException: Connection reset\n",
      "\tat java.base/java.net.SocketInputStream.read(SocketInputStream.java:186)\n",
      "\tat java.base/java.net.SocketInputStream.read(SocketInputStream.java:140)\n",
      "\tat java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)\n",
      "\tat java.base/java.io.BufferedInputStream.read1(BufferedInputStream.java:292)\n",
      "\tat java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:351)\n",
      "\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:200)\n",
      "\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:170)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:758)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:747)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:512)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:760)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat scala.collection.convert.Wrappers$IteratorWrapper.hasNext(Wrappers.scala:32)\n",
      "\tat org.sparkproject.guava.collect.Ordering.leastOf(Ordering.java:670)\n",
      "\tat org.apache.spark.util.collection.Utils$.takeOrdered(Utils.scala:37)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$takeOrdered$2(RDD.scala:1539)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:855)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:855)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:136)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "22/10/24 09:32:10 ERROR PythonRunner: This may have been caused by a prior exception:\n",
      "java.net.SocketException: Broken pipe (Write failed)\n",
      "\tat java.base/java.net.SocketOutputStream.socketWrite0(Native Method)\n",
      "\tat java.base/java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:110)\n",
      "\tat java.base/java.net.SocketOutputStream.write(SocketOutputStream.java:150)\n",
      "\tat java.base/java.io.BufferedOutputStream.write(BufferedOutputStream.java:123)\n",
      "\tat java.base/java.io.DataOutputStream.write(DataOutputStream.java:107)\n",
      "\tat java.base/java.io.FilterOutputStream.write(FilterOutputStream.java:108)\n",
      "\tat org.apache.spark.api.python.PythonRDD$.write$1(PythonRDD.scala:295)\n",
      "\tat org.apache.spark.api.python.PythonRDD$.$anonfun$writeIteratorToStream$1(PythonRDD.scala:307)\n",
      "\tat org.apache.spark.api.python.PythonRDD$.$anonfun$writeIteratorToStream$1$adapted(PythonRDD.scala:307)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
      "\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n",
      "\tat org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:307)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$2.writeIteratorToStream(PythonRunner.scala:732)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$WriterThread.$anonfun$run$1(PythonRunner.scala:438)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$WriterThread.run(PythonRunner.scala:272)\n",
      "22/10/24 09:32:10 ERROR Executor: Exception in task 3.0 in stage 13.0 (TID 66)\n",
      "java.net.SocketException: Broken pipe (Write failed)\n",
      "\tat java.base/java.net.SocketOutputStream.socketWrite0(Native Method)\n",
      "\tat java.base/java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:110)\n",
      "\tat java.base/java.net.SocketOutputStream.write(SocketOutputStream.java:150)\n",
      "\tat java.base/java.io.BufferedOutputStream.write(BufferedOutputStream.java:123)\n",
      "\tat java.base/java.io.DataOutputStream.write(DataOutputStream.java:107)\n",
      "\tat java.base/java.io.FilterOutputStream.write(FilterOutputStream.java:108)\n",
      "\tat org.apache.spark.api.python.PythonRDD$.write$1(PythonRDD.scala:295)\n",
      "\tat org.apache.spark.api.python.PythonRDD$.$anonfun$writeIteratorToStream$1(PythonRDD.scala:307)\n",
      "\tat org.apache.spark.api.python.PythonRDD$.$anonfun$writeIteratorToStream$1$adapted(PythonRDD.scala:307)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
      "\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n",
      "\tat org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:307)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$2.writeIteratorToStream(PythonRunner.scala:732)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$WriterThread.$anonfun$run$1(PythonRunner.scala:438)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$WriterThread.run(PythonRunner.scala:272)\n",
      "22/10/24 09:32:10 WARN TaskSetManager: Lost task 3.0 in stage 13.0 (TID 66) (192.168.0.202 executor driver): java.net.SocketException: Broken pipe (Write failed)\n",
      "\tat java.base/java.net.SocketOutputStream.socketWrite0(Native Method)\n",
      "\tat java.base/java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:110)\n",
      "\tat java.base/java.net.SocketOutputStream.write(SocketOutputStream.java:150)\n",
      "\tat java.base/java.io.BufferedOutputStream.write(BufferedOutputStream.java:123)\n",
      "\tat java.base/java.io.DataOutputStream.write(DataOutputStream.java:107)\n",
      "\tat java.base/java.io.FilterOutputStream.write(FilterOutputStream.java:108)\n",
      "\tat org.apache.spark.api.python.PythonRDD$.write$1(PythonRDD.scala:295)\n",
      "\tat org.apache.spark.api.python.PythonRDD$.$anonfun$writeIteratorToStream$1(PythonRDD.scala:307)\n",
      "\tat org.apache.spark.api.python.PythonRDD$.$anonfun$writeIteratorToStream$1$adapted(PythonRDD.scala:307)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
      "\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n",
      "\tat org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:307)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$2.writeIteratorToStream(PythonRunner.scala:732)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$WriterThread.$anonfun$run$1(PythonRunner.scala:438)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$WriterThread.run(PythonRunner.scala:272)\n",
      "\n",
      "22/10/24 09:32:10 ERROR TaskSetManager: Task 3 in stage 13.0 failed 1 times; aborting job\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    cases.select('case_closed', 'case_lifetime')\n",
    "    .filter('! case_closed')\n",
    "    .sort(desc(\"num_days_late\"))\n",
    "    .where(\"num_days_late != 'nan'\")\n",
    ").show(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791c0d70-722c-4677-9a68-a0514c354a56",
   "metadata": {},
   "source": [
    "2. How many Stray Animal cases are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ca62c9ff-d43d-49ff-8067-4bb7ac3a2cea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/24 09:32:34 WARN TaskSetManager: Stage 16 contains a task of very large size (15174 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 16:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/24 09:32:38 WARN PythonRunner: Detected deadlock while completing task 0.0 in stage 16 (TID 84): Attempting to kill Python Worker\n",
      "+--------------------+\n",
      "|service_request_type|\n",
      "+--------------------+\n",
      "|        Stray Animal|\n",
      "|Removal Of Obstru...|\n",
      "|Removal Of Obstru...|\n",
      "|Front Or Side Yar...|\n",
      "|Animal Cruelty(Cr...|\n",
      "+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "cases.select('service_request_type').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a61d9ba1-bc55-4fa5-9282-f3fa15bf0297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/24 09:34:03 WARN TaskSetManager: Stage 21 contains a task of very large size (15174 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "26760"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    cases.filter(expr('service_request_type == \"Stray Animal\"')).count()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4d5643-2466-46d1-8f52-912839d235c9",
   "metadata": {},
   "source": [
    "3. How many service requests that are assigned to the Field Operations department (dept_division) are not classified as \"Officer Standby\" request type (service_request_type)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "564aca53-ed1c-429b-8ce9-1556b17a528a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/24 09:36:46 WARN TaskSetManager: Stage 25 contains a task of very large size (15174 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "113902"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 24:===================================================>     (9 + 1) / 10]\r"
     ]
    }
   ],
   "source": [
    "(\n",
    "    cases.filter(cases.dept_division == 'Field Operations')\n",
    "    .filter(cases.service_request_type != 'Officer Standby')\n",
    ").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5d5ec5-02bc-4870-a1eb-5ada359fedd7",
   "metadata": {},
   "source": [
    "4. Convert the council_district column to a string column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "15ce63fd-652a-48b7-b94a-231239300ab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('case_id', 'bigint'),\n",
       " ('case_opened_date', 'timestamp'),\n",
       " ('case_closed_date', 'timestamp'),\n",
       " ('case_due_date', 'timestamp'),\n",
       " ('case_late', 'boolean'),\n",
       " ('num_days_late', 'double'),\n",
       " ('case_closed', 'boolean'),\n",
       " ('dept_division', 'string'),\n",
       " ('service_request_type', 'string'),\n",
       " ('SLA_days', 'double'),\n",
       " ('case_status', 'string'),\n",
       " ('source_id', 'string'),\n",
       " ('request_address', 'string'),\n",
       " ('council_district', 'string'),\n",
       " ('case_age', 'int'),\n",
       " ('days_to_close', 'int'),\n",
       " ('case_lifetime', 'int')]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cases.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7847a76a-6cc6-47a6-bf74-958cf4c4857f",
   "metadata": {},
   "source": [
    "5. Extract the year from the case_closed_date column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bc67fe32-6431-47af-a763-3e7abbd47943",
   "metadata": {},
   "outputs": [],
   "source": [
    "cases = cases.withColumn('case_closed_year',\n",
    "                year('case_closed_date'))#.select('case_closed_date', 'case_closed_year').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8857d93f-4815-404c-abce-f42bb7a49441",
   "metadata": {},
   "source": [
    "6. Convert num_days_late from days to hours in new columns num_hours_late."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "67280f38-26e5-4109-918c-a9e29a51d5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "cases = cases.withColumn('num_hours_late',\n",
    "                expr('num_days_late * 24'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "69a0217a-c580-4d0b-a50b-e3bdfabca4e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/24 09:39:47 WARN TaskSetManager: Stage 29 contains a task of very large size (15174 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 29:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/24 09:39:51 WARN PythonRunner: Detected deadlock while completing task 0.0 in stage 29 (TID 130): Attempting to kill Python Worker\n",
      "+-------------------+-------------+\n",
      "|     num_hours_late|num_days_late|\n",
      "+-------------------+-------------+\n",
      "|-23964.210278399998| -998.5087616|\n",
      "|      -48.302500008| -2.012604167|\n",
      "|      -72.536111112| -3.022337963|\n",
      "|      -360.27555552| -15.01148148|\n",
      "|        8.931944448|  0.372164352|\n",
      "+-------------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "cases.select('num_hours_late', 'num_days_late').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2015ef5-97a4-4dd8-acba-b4b5069cf382",
   "metadata": {},
   "source": [
    "7. Join the case data with the source and department data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "88a773a3-f415-4a7c-a761-540d08a61275",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['case_id',\n",
       " 'case_opened_date',\n",
       " 'case_closed_date',\n",
       " 'case_due_date',\n",
       " 'case_late',\n",
       " 'num_days_late',\n",
       " 'case_closed',\n",
       " 'dept_division',\n",
       " 'service_request_type',\n",
       " 'SLA_days',\n",
       " 'case_status',\n",
       " 'source_id',\n",
       " 'request_address',\n",
       " 'council_district',\n",
       " 'case_age',\n",
       " 'days_to_close',\n",
       " 'case_lifetime',\n",
       " 'case_closed_year',\n",
       " 'num_hours_late']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cases.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "829ad740-9f66-4080-be1f-529c2e7d403d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['index', 'source_id', 'source_username']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c20cb854-5bab-4bb1-8762-3f9fa43ed5a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dept_division', 'dept_name', 'standardized_dept_name', 'dept_subject_to_SLA']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dept.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cc21c249-00e7-40e0-b23d-e6e4fad0d39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cases.join(dept, 'dept_division', 'left').join(source, 'source_id', 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5cf71854-e2b7-4c7a-855b-2e39131e09a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['source_id',\n",
       " 'dept_division',\n",
       " 'case_id',\n",
       " 'case_opened_date',\n",
       " 'case_closed_date',\n",
       " 'case_due_date',\n",
       " 'case_late',\n",
       " 'num_days_late',\n",
       " 'case_closed',\n",
       " 'service_request_type',\n",
       " 'SLA_days',\n",
       " 'case_status',\n",
       " 'request_address',\n",
       " 'council_district',\n",
       " 'case_age',\n",
       " 'days_to_close',\n",
       " 'case_lifetime',\n",
       " 'case_closed_year',\n",
       " 'num_hours_late',\n",
       " 'dept_name',\n",
       " 'standardized_dept_name',\n",
       " 'dept_subject_to_SLA',\n",
       " 'index',\n",
       " 'source_username']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b63576-f52c-4878-b852-9a85207e275f",
   "metadata": {},
   "source": [
    "8. Are there any cases that do not have a request source?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "342b6e9f-dd23-4077-b01f-145890e8d9aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/24 09:49:28 WARN TaskSetManager: Stage 30 contains a task of very large size (15174 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter(expr('index is null')).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cdf9de52-5f42-4a42-87f3-8f56c5865536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# none. All have a request source"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7110a8-a71e-4c38-94d9-93766d7aa024",
   "metadata": {},
   "source": [
    "9. What are the top 10 service request types in terms of number of requests?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e20273fa-5446-4c5b-82e0-251faf71666a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/24 09:51:53 WARN TaskSetManager: Stage 66 contains a task of very large size (15174 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------+-----+\n",
      "|service_request_type            |count|\n",
      "+--------------------------------+-----+\n",
      "|No Pickup                       |89210|\n",
      "|Overgrown Yard/Trash            |66403|\n",
      "|Bandit Signs                    |32968|\n",
      "|Damaged Cart                    |31163|\n",
      "|Front Or Side Yard Parking      |28920|\n",
      "|Stray Animal                    |27361|\n",
      "|Aggressive Animal(Non-Critical) |25492|\n",
      "|Cart Exchange Request           |22608|\n",
      "|Junk Vehicle On Private Property|21649|\n",
      "|Pot Hole Repair                 |20827|\n",
      "+--------------------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    df.groupBy('service_request_type').count()\n",
    "    .sort(desc('count'))\n",
    ").show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cff3dd6-f14f-4bad-a5bb-17b1bada0da7",
   "metadata": {},
   "source": [
    "10. What are the top 10 service request types in terms of average days late?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "23ee823e-448e-408c-8b76-5b94943af0f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/24 09:54:46 WARN TaskSetManager: Stage 102 contains a task of very large size (15174 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------+-------------+\n",
      "|service_request_type                  |avg_days_late|\n",
      "+--------------------------------------+-------------+\n",
      "|Zoning: Junk Yards                    |175.96       |\n",
      "|Labeling for Used Mattress            |162.43       |\n",
      "|Record Keeping of Used Mattresses     |154.0        |\n",
      "|Signage Requied for Sale of Used Mattr|151.64       |\n",
      "|Storage of Used Mattress              |142.11       |\n",
      "|Zoning: Recycle Yard                  |135.93       |\n",
      "|Donation Container Enforcement        |131.76       |\n",
      "|License Requied Used Mattress Sales   |128.8        |\n",
      "|Traffic Signal Graffiti               |101.8        |\n",
      "|Complaint                             |72.87        |\n",
      "+--------------------------------------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    df.groupby('service_request_type')\n",
    "    .agg(round(mean('num_days_late'), 2).alias('avg_days_late'))\n",
    "    .sort(desc('avg_days_late'))\n",
    "    .na.drop()\n",
    ").show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488fd4f3-2519-4ea8-b600-d9a58f2cf5b2",
   "metadata": {},
   "source": [
    "11. Does number of days late depend on department?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "173c1f19-aa64-4ba4-bd2f-7d9cf0aee5d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/24 10:02:51 WARN TaskSetManager: Stage 145 contains a task of very large size (15174 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+-------------------+\n",
      "|dept_name                |avg(num_days_late) |\n",
      "+-------------------------+-------------------+\n",
      "|Animal Care Services     |-226.51783940550436|\n",
      "|null                     |135.92851612479797 |\n",
      "|Solid Waste Management   |-2.2000575136721845|\n",
      "|Development Services     |13.433724555869714 |\n",
      "|Trans & Cap Improvements |-20.6128373540527  |\n",
      "|Customer Service         |59.737091496300785 |\n",
      "|Metro Health             |-4.911766979607001 |\n",
      "|Parks and Recreation     |-5.251521960055142 |\n",
      "|Code Enforcement Services|-38.70133068329558 |\n",
      "|City Council             |NaN                |\n",
      "+-------------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    df.groupby('dept_name')\n",
    "    .mean('num_days_late')\n",
    ").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1033e523-e75d-4277-8239-17f9743e33d7",
   "metadata": {},
   "source": [
    "12. How do number of days late depend on department and request type?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4a946af2-3350-4fdb-a104-a1ace9591d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/24 10:03:31 WARN TaskSetManager: Stage 157 contains a task of very large size (15174 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 165:>                                                        (0 + 4) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+----------------------------------------+--------------------+\n",
      "|dept_name                |service_request_type                    |avg(num_days_late)  |\n",
      "+-------------------------+----------------------------------------+--------------------+\n",
      "|null                     |Zoning: Recycle Yard                    |135.92851612479797  |\n",
      "|Animal Care Services     |Aggressive Animal(Critical)             |16.696368811892242  |\n",
      "|Animal Care Services     |City Council Animal Request             |-1.5475013634821913 |\n",
      "|Animal Care Services     |Stray Animal                            |-998.8064665118975  |\n",
      "|Animal Care Services     |Animal Bite(Critical)                   |0.019096834813110194|\n",
      "|Animal Care Services     |Officer Standby                         |-0.06756953501177049|\n",
      "|Animal Care Services     |Animal Permits Request                  |22.197922714476803  |\n",
      "|Animal Care Services     |Aggressive Animal(Non-Critical)         |2.645033883163259   |\n",
      "|Animal Care Services     |Animal Bite(Non-Critical)               |-2.5056675479734483 |\n",
      "|Animal Care Services     |Spay/Neuter Request Response            |-6.976550926        |\n",
      "|Animal Care Services     |Animal Cruelty(Critical)                |-0.06219277353522764|\n",
      "|Animal Care Services     |Public Nuisance(Own Animal)             |-2.204561124319811  |\n",
      "|Animal Care Services     |Injured Animal(Critical)                |-0.06529248474639537|\n",
      "|Animal Care Services     |Animal Neglect                          |7.332927878069391   |\n",
      "|Animal Care Services     |Trapped/Confined Animal                 |0.24904801968872053 |\n",
      "|City Council             |Request for Research/Information        |NaN                 |\n",
      "|City Council             |CCO_Request for Research/Information_1  |NaN                 |\n",
      "|Code Enforcement Services|Zoning Business in Resident Area        |-111.55088638720373 |\n",
      "|Code Enforcement Services|Improper Rec Keeping-Used/Scrap Tire Fac|-79.78437676840679  |\n",
      "|Code Enforcement Services|Animal Investigation Referral           |-40.95604321        |\n",
      "+-------------------------+----------------------------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "(\n",
    "    df.groupby('dept_name', 'service_request_type')\n",
    "    .mean('num_days_late')\n",
    "    .sort('dept_name')\n",
    ").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eceda46-2ac9-4c2a-9016-19bc6bb1c8ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
